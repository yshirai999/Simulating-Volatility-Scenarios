{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments using Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from Transformer import Transformer, Transformer2D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Base Env params\n",
    "\n",
    "# need to make feature and target steps the same for the embedding\n",
    "feature_steps =  1008\n",
    "target_steps = 1\n",
    "\n",
    "input_dim  = 1\n",
    "d_model = 64\n",
    "output_dim = 1\n",
    "num_heads = 2\n",
    "num_layers = 3\n",
    "dim_feedforward = 256\n",
    "seq_length = 6000 # max sequence length of the time series\n",
    "dropout = 0.1\n",
    "quantized = True\n",
    "quant_all = True\n",
    "weight_scale = 1e2\n",
    "num_epochs = 100\n",
    "n_clusters = 20\n",
    "quantiles=(0.25,0.75)\n",
    "device = 'cpu' # 'cuda' or 'cpu'. For 'cuda', requires GPU compatible with CUDA version 11.8 or higher, and PyTorch version 2.0 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601979, 4)\n",
      "dict_keys([1, 2, 3, 4])\n",
      "4\n",
      "9\n",
      "Training for 10 epochs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Transformer2D(tickers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspy\u001b[39m\u001b[38;5;124m'\u001b[39m], target_steps\u001b[38;5;241m=\u001b[39mtarget_steps,feature_steps\u001b[38;5;241m=\u001b[39mfeature_steps, scaler\u001b[38;5;241m=\u001b[39mStandardScaler,\n\u001b[1;32m      8\u001b[0m     input_dim\u001b[38;5;241m=\u001b[39minput_dim, d_model\u001b[38;5;241m=\u001b[39md_model, num_heads\u001b[38;5;241m=\u001b[39mnum_heads, num_layers\u001b[38;5;241m=\u001b[39mnum_layers,\n\u001b[1;32m      9\u001b[0m     dim_feedforward\u001b[38;5;241m=\u001b[39mdim_feedforward, output_dim\u001b[38;5;241m=\u001b[39moutput_dim, seq_length\u001b[38;5;241m=\u001b[39mseq_length, dropout\u001b[38;5;241m=\u001b[39mdropout, quantized\u001b[38;5;241m=\u001b[39mquantized, quant_all\u001b[38;5;241m=\u001b[39mquant_all,\n\u001b[1;32m     10\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39mn_clusters, scale\u001b[38;5;241m=\u001b[39mweight_scale, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, quantiles\u001b[38;5;241m=\u001b[39mquantiles, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict()\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mplot_quantile_predicitons(t\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspy\u001b[39m\u001b[38;5;124m\"\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Weight Init Scale = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_scale\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Quantized:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquantized\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py:386\u001b[0m, in \u001b[0;36mTransformer2D.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=382'>383</a>\u001b[0m y_train \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=383'>384</a>\u001b[0m y_valid \u001b[39m=\u001b[39m y_valid\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=385'>386</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_errors[t], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_errors[t] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodels[t]\u001b[39m.\u001b[39;49mtrain_model(X_train\u001b[39m=\u001b[39;49mX_train, y_train\u001b[39m=\u001b[39;49my_train, X_val\u001b[39m=\u001b[39;49mX_valid, y_val\u001b[39m=\u001b[39;49my_valid, num_epochs \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_epochs)\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=386'>387</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinal Train loss : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_errors[t][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m final Val loss: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_errors[t][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py:194\u001b[0m, in \u001b[0;36mTransformerModel.train_model\u001b[0;34m(self, X_train, y_train, X_val, y_val, num_epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=190'>191</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m X_train[i:i\u001b[39m+\u001b[39mbatch_size]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=191'>192</a>\u001b[0m labels \u001b[39m=\u001b[39m y_train[i:i\u001b[39m+\u001b[39mbatch_size]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=193'>194</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=194'>195</a>\u001b[0m loss \u001b[39m=\u001b[39m crit(output, labels)\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=195'>196</a>\u001b[0m \u001b[39m# print(f\"loss = {loss}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py:133\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=129'>130</a>\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(src)\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=130'>131</a>\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(src)\n\u001b[0;32m--> <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=132'>133</a>\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer\u001b[39m.\u001b[39;49mencoder(src)  \u001b[39m# (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=133'>134</a>\u001b[0m last_step_output \u001b[39m=\u001b[39m transformer_output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]  \u001b[39m# Take the last timestep (batch_size, d_model)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/jacobyoung/CFRMResearch/Simulating-Volatility-Scenarios/Transformer.py?line=135'>136</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer(last_step_output)  \u001b[39m# (batch_size, output_dim)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1508'>1509</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1509'>1510</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1510'>1511</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1514'>1515</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1518'>1519</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1519'>1520</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:391\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=387'>388</a>\u001b[0m is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=389'>390</a>\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=390'>391</a>\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=392'>393</a>\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=393'>394</a>\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m/opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1508'>1509</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1509'>1510</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1510'>1511</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1514'>1515</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1518'>1519</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1519'>1520</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=712'>713</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=713'>714</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39mis_causal))\n\u001b[0;32m--> <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=714'>715</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ff_block(x))\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=716'>717</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:730\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=728'>729</a>\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_ff_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=729'>730</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear1(x))))\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/simenv/lib/python3.10/site-packages/torch/nn/modules/transformer.py?line=730'>731</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = [10, 25, 50, 100]\n",
    "input_dim = 2\n",
    "#output_dim = 2\n",
    "output_dim = 4\n",
    "for e in epoch_list:\n",
    "    num_epochs = e\n",
    "    model = Transformer2D(tickers=['spy'], target_steps=target_steps,feature_steps=feature_steps, scaler=StandardScaler,\n",
    "        input_dim=input_dim, d_model=d_model, num_heads=num_heads, num_layers=num_layers,\n",
    "        dim_feedforward=dim_feedforward, output_dim=output_dim, seq_length=seq_length, dropout=dropout, quantized=quantized, quant_all=quant_all,\n",
    "        n_clusters=n_clusters, scale=weight_scale, num_epochs=num_epochs, quantiles=quantiles, device=device)\n",
    "    print(f\"Training for {e} epochs\")\n",
    "    model.train()\n",
    "    model.predict()\n",
    "    model.plot_quantile_predicitons(t=\"spy\", title=f\"num_epochs={num_epochs}, Weight Init Scale = {weight_scale}, Quantized:{quantized}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_list = [10,25, 50,100]\n",
    "# input_dim = 1\n",
    "# output_dim = 1\n",
    "# for e in epoch_list:\n",
    "#     num_epochs = e\n",
    "#     model = Transformer(tickers=['spy'], target_steps=target_steps,feature_steps=feature_steps, scaler=StandardScaler,\n",
    "#         input_dim=input_dim, d_model=d_model, num_heads=num_heads, num_layers=num_layers, n_clusters=n_clusters,\n",
    "#         dim_feedforward=dim_feedforward, output_dim=output_dim, seq_length=seq_length, dropout=dropout, quantized=quantized, scale=weight_scale, num_epochs=num_epochs)\n",
    "#     print(f\"Training for {e} epochs\")\n",
    "#     model.train()\n",
    "#     model.predict()\n",
    "#     model.plot_predictions(t=\"spy\", title=f\"num_epochs={num_epochs}, Weight Init Scale = {weight_scale}, Quantized:{quantized}\")\n",
    "#     print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
